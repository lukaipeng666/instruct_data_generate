#!/usr/bin/env python3
"""
æ•°æ®ç”Ÿæˆè„šæœ¬
è¯»å–æ ·æœ¬æ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ç”Ÿæˆæ–°æ•°æ®ï¼Œè¿›è¡Œè¯„ä¼°å¹¶ä¿å­˜åˆæ ¼çš„æ•°æ®
"""

import json
import traceback
import os
import argparse
import asyncio
import aiohttp
import time
import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging
from pathlib import Path
import sys
import random

# å¯¼å…¥å·¥å…·å‡½æ•°
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.tools import (
    get_prompt_builder,
    get_format_evaluator
)

# é…ç½®æ—¥å¿—
os.makedirs('log', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('log/data_generation_.log', mode='w'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class DataGenerator:
    def __init__(self, 
                 api_base: str = "http://localhost:6466/v1",
                 model: str = "/data/models/Qwen3-32B",
                 max_concurrent: int = 5,
                 retry_times: int = 3,
                 min_score: int = 9,
                 task_type: str = "entity_extraction",
                 variants_per_sample: int = 3,
                 sample_retry_times: int = 3,
                 special_prompt: str = "",
                 directions: list = ["ä¿¡ç”¨å¡å¹´è´¹"]):
        self.api_base = api_base
        self.model = model
        self.max_concurrent = max_concurrent
        self.retry_times = retry_times  # APIè°ƒç”¨é‡è¯•æ¬¡æ•°
        self.sample_retry_times = sample_retry_times  # æ ·æœ¬å¤„ç†é‡è¯•æ¬¡æ•°
        self.min_score = min_score  # æœ€ä½åˆ†æ•°è¦æ±‚
        self.task_type = task_type
        self.variants_per_sample = variants_per_sample
        self.session = None
        self.stats = {
            'samples_read': 0,
            'data_generated': 0,
            'data_evaluated': 0,
            'data_passed': 0,
            'data_failed': 0,
            'api_errors': 0,
            'sample_retries': 0  # æ–°å¢ï¼šæ ·æœ¬é‡è¯•æ¬¡æ•°ç»Ÿè®¡
        }
        
        # è·å–å¯é…ç½®çš„å‡½æ•°
        self.generation_prompt_builder = get_prompt_builder('generation')
        self.evaluation_prompt_builder = get_prompt_builder('evaluation')
        self.format_evaluator = get_format_evaluator(task_type)
        self.filter_prompt = get_prompt_builder('filter')
        self.special_prompt = special_prompt
        self.directions = directions
    
    async def init_session(self):
        """åˆå§‹åŒ–HTTPä¼šè¯"""
        timeout = aiohttp.ClientTimeout(total=600)  
        self.session = aiohttp.ClientSession(timeout=timeout)
    
    async def close_session(self):
        """å…³é—­HTTPä¼šè¯"""
        if self.session:
            await self.session.close()
    
    async def call_api(self, prompt: str, temperature: float = 0.6) -> Optional[str]:
        """è°ƒç”¨æœ¬åœ°API"""
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": temperature,
            "max_tokens": 8096,
            "stream": True
        }
        
        full_response = ""
        for attempt in range(self.retry_times):
            try:
                async with self.session.post(
                    f"{self.api_base}/chat/completions",
                    json=payload,
                    headers={"Content-Type": "application/json"},
                ) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        logger.warning(f"APIè°ƒç”¨å¤±è´¥ (çŠ¶æ€ç : {response.status}): {error_text}")
                        if attempt < self.retry_times - 1:
                            await asyncio.sleep(2 ** attempt)
                        continue

                    async for line in response.content:
                        line = line.strip().decode('utf-8')
                        if not line:
                            continue
                        if line.startswith("data: "):
                            data_str = line[6:]
                            if data_str == "[DONE]":
                                return full_response.strip()
                            try:
                                data = json.loads(data_str)
                                delta = data["choices"][0]["delta"].get("content", "")
                                if delta:
                                    full_response += delta
                                    # print(delta, end="", flush=True)
                            except (KeyError, json.JSONDecodeError) as e:
                                logger.debug(f"è§£ææµæ•°æ®å¤±è´¥: {data_str}")
                                continue
                    return full_response.strip()

            except asyncio.TimeoutError:
                logger.warning(f"APIè°ƒç”¨è¶…æ—¶ (å°è¯• {attempt + 1}/{self.retry_times})")
            except aiohttp.ClientConnectorError as e:
                logger.warning(f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{self.retry_times}): {e!r}")
            except aiohttp.ServerDisconnectedError:
                logger.warning(f"æœåŠ¡å™¨æ–­å¼€è¿æ¥ (å°è¯• {attempt + 1}/{self.retry_times})")
            except aiohttp.ClientResponseError as e:
                logger.warning(f"å“åº”é”™è¯¯ (çŠ¶æ€ç : {e.status}): {e.message}")
            except Exception as e:
                logger.warning(f"æœªé¢„æœŸå¼‚å¸¸ {type(e).__name__} (å°è¯• {attempt + 1}/{self.retry_times}): {str(e) or repr(e)}")
                logger.debug(f"è¯¦ç»†å †æ ˆ: {traceback.format_exc()}")

            if attempt < self.retry_times - 1:
                await asyncio.sleep(2 ** attempt)
        
        self.stats['api_errors'] += 1
        return None
    
    def parse_generated_data(self, response: str, batch_idx: int = None, thread_idx: int = None, is_main_batch: bool = False, is_main_thread: bool = False) -> List[Dict[str, Any]]:
        """è§£æç”Ÿæˆçš„æ•°æ®
        
        Args:
            response: æ¨¡å‹è¾“å‡ºçš„åŸå§‹å“åº”
            batch_idx: æ‰¹æ¬¡ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            thread_idx: çº¿ç¨‹/æ ·æœ¬ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            is_main_batch: æ˜¯å¦ä¸ºä¸»æ‰¹æ¬¡ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼‰
            is_main_thread: æ˜¯å¦ä¸ºä¸»çº¿ç¨‹ï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
        """
        # å°è¯•æå–JSONå†…å®¹
        try:
            # æ–¹æ³•1: æŸ¥æ‰¾JSONä»£ç å—
            # æ³¨æ„ï¼šä½¿ç”¨è´ªå©ªåŒ¹é…(.*)è€Œä¸æ˜¯éè´ªå©ªåŒ¹é…(.*?)
            # å› ä¸ºæ¨¡å‹è¾“å‡ºçš„textå­—æ®µä¸­å¯èƒ½åŒ…å«```ç¬¦å·ï¼Œéè´ªå©ªåŒ¹é…ä¼šè¿‡æ—©ç»“æŸ
            json_pattern = r'```json\s*(.*)\s*```'
            json_match = re.search(json_pattern, response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                try:
                    data = json.loads(json_str)
                    if isinstance(data, list):
                        logger.info("âœ… æˆåŠŸè§£æJSONæ•°ç»„")
                        logger.info(f"ğŸ“Š è§£æåçš„æ•°æ®é•¿åº¦: {len(data)}")
                        if len(data) > 0:
                            logger.info(f"ğŸ“Š ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç»“æ„: {json.dumps(data[0], ensure_ascii=False, indent=2)[:300]}")
                        return data
                    elif isinstance(data, dict):
                        logger.info("âœ… æˆåŠŸè§£æJSONå¯¹è±¡ï¼ˆè½¬æ¢ä¸ºåˆ—è¡¨ï¼‰")
                        return [data]
                except json.JSONDecodeError as e:
                    logger.warning(f"JSONè§£æå¤±è´¥: {e}")
            
            # æ–¹æ³•2: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
            try:
                data = json.loads(response.strip())
                if isinstance(data, list):
                    logger.info("âœ… æˆåŠŸè§£ææ•´ä¸ªå“åº”ä¸ºJSONæ•°ç»„")
                    return data
                elif isinstance(data, dict):
                    logger.info("âœ… æˆåŠŸè§£ææ•´ä¸ªå“åº”ä¸ºJSONå¯¹è±¡ï¼ˆè½¬æ¢ä¸ºåˆ—è¡¨ï¼‰")
                    return [data]
            except json.JSONDecodeError:
                pass
            
            # æ–¹æ³•3: æŸ¥æ‰¾ä»¥[å¼€å¤´]ç»“å°¾çš„æ•°ç»„
            # ä½¿ç”¨è´ªå©ªåŒ¹é…(.*)åŒ¹é…åˆ°æœ€åä¸€ä¸ª]ï¼Œé¿å…åµŒå¥—æ•°ç»„åŒ¹é…é”™è¯¯
            array_pattern = r'\[.*\]'
            array_match = re.search(array_pattern, response, re.DOTALL)
            if array_match:
                array_str = array_match.group(0)
                try:
                    data = json.loads(array_str)
                    if isinstance(data, list):
                        logger.info("âœ… æˆåŠŸä»æ•°ç»„æ¨¡å¼æå–å¹¶è§£æJSON")
                        return data
                except json.JSONDecodeError as e:
                    logger.warning(f"æ•°ç»„æ¨¡å¼JSONè§£æå¤±è´¥: {e}")
            
            # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
            # å¦‚æœæ˜¯ä¸»æ‰¹æ¬¡çš„ä¸»çº¿ç¨‹ï¼Œæ‰“å°è¯¦ç»†æ—¥å¿—
            if is_main_batch and is_main_thread:
                logger.error("=" * 80)
                logger.error("ã€ä¸»æ‰¹æ¬¡ä¸»çº¿ç¨‹ã€‘æ¨¡å‹è¾“å‡ºè§£æå¤±è´¥ - è¯¦ç»†æ—¥å¿—")
                logger.error(f"æ‰¹æ¬¡ç´¢å¼•: {batch_idx}, çº¿ç¨‹ç´¢å¼•: {thread_idx}")
                logger.error("æ‰€æœ‰è§£ææ–¹æ³•å‡å¤±è´¥")
                logger.error("=" * 80)
                logger.error("å®Œæ•´æ¨¡å‹è¾“å‡º:")
                logger.error(response)
                logger.error("=" * 80)
                # å°è¯•åˆ†æé—®é¢˜
                if "```json" in response:
                    logger.error("æ£€æµ‹åˆ°```jsonæ ‡è®°ï¼Œä½†å†…å®¹æ— æ³•è§£æ")
                elif "[" in response and "]" in response:
                    logger.error("æ£€æµ‹åˆ°æ•°ç»„æ ‡è®°[]ï¼Œä½†å†…å®¹æ— æ³•è§£æ")
                else:
                    logger.error("æœªæ£€æµ‹åˆ°JSONæ ¼å¼æ ‡è®°")
            return []
            
        except Exception as e:
            logger.warning(f"è§£æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
            # å¦‚æœæ˜¯ä¸»æ‰¹æ¬¡çš„ä¸»çº¿ç¨‹ï¼Œæ‰“å°è¯¦ç»†æ—¥å¿—
            if is_main_batch and is_main_thread:
                logger.error("=" * 80)
                logger.error("ã€ä¸»æ‰¹æ¬¡ä¸»çº¿ç¨‹ã€‘æ¨¡å‹è¾“å‡ºè§£æå¼‚å¸¸ - è¯¦ç»†æ—¥å¿—")
                logger.error(f"æ‰¹æ¬¡ç´¢å¼•: {batch_idx}, çº¿ç¨‹ç´¢å¼•: {thread_idx}")
                logger.error(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                logger.error(f"å¼‚å¸¸ä¿¡æ¯: {e}")
                logger.error("=" * 80)
                logger.error("å®Œæ•´æ¨¡å‹è¾“å‡º:")
                logger.error(response)
                logger.error("=" * 80)
            return []

    def parse_evaluation_score(self, response: str) -> Optional[int]:
        """è§£æè¯„ä¼°åˆ†æ•°"""
        import re
        
        # ä¼˜å…ˆæŸ¥æ‰¾\\boxed{}æ ¼å¼çš„è¯„åˆ†
        boxed_pattern = r'\\boxed\{(\d+)\}'
        boxed_match = re.search(boxed_pattern, response)
        if boxed_match:
            score = int(boxed_match.group(1))
            if 0 <= score <= 10:
                return score
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾æœ€åä¸€è¡Œçš„æ•°å­—è¯„åˆ†
        lines = response.strip().split('\n')
        for line in reversed(lines):
            line = line.strip()
            if line.isdigit() and 0 <= int(line) <= 10:
                return int(line)
        
        return None
    
    async def generate_data_from_sample(self, sample_data: Dict[str, Any], batch_idx: int = None, thread_idx: int = None, is_main_batch: bool = False, is_main_thread: bool = False) -> List[Dict[str, Any]]:
        """æ ¹æ®æ ·æœ¬æ•°æ®ç”Ÿæˆæ–°æ•°æ®
        
        Args:
            sample_data: æ ·æœ¬æ•°æ®
            batch_idx: æ‰¹æ¬¡ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            thread_idx: çº¿ç¨‹/æ ·æœ¬ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            is_main_batch: æ˜¯å¦ä¸ºä¸»æ‰¹æ¬¡ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼‰
            is_main_thread: æ˜¯å¦ä¸ºä¸»çº¿ç¨‹ï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
        """
        try:
            # æ„å»ºç”Ÿæˆæç¤º
            if self.task_type == "calculation":
                if self.directions == "éªŒè¯ç ":
                    # éšæœºç”Ÿæˆ4ä½æˆ–6ä½æ•°å­—éªŒè¯ç 
                    length = random.choice([4, 6])
                    verification_code = ''.join(str(random.randint(0, 9)) for _ in range(length))
                    result = [f"éšæœºç”Ÿæˆçš„{length}ä½éªŒè¯ç ï¼š{verification_code}"]
                elif self.directions == "æ‰‹æœºå·ç ":
                    # éšæœºç”Ÿæˆ11ä½ä¸­å›½å¤§é™†æ‰‹æœºå·ï¼ˆé¦–ä½å›ºå®šä¸º1ï¼Œç¬¬äºŒä½å¸¸è§ä¸º3/4/5/7/8ï¼‰
                    first = '1'
                    second = random.choice(['3', '4', '5', '7', '8'])
                    rest = ''.join(str(random.randint(0, 9)) for _ in range(9))
                    phone_number = first + second + rest
                    result = [f"éšæœºç”Ÿæˆçš„11ä½æ‰‹æœºå·ç ï¼š{phone_number}"]
                elif self.directions == "èº«ä»½è¯å·ç ":
                    # éšæœºç”Ÿæˆ18ä½èº«ä»½è¯å·ï¼ˆå‰6ä½åœ°å€ç ç®€åŒ–å¤„ç†ï¼Œç¬¬7-14ä½ç”Ÿæ—¥éšæœºï¼Œæœ€å1ä½å¯èƒ½ä¸ºXï¼‰
                    address_code = ''.join(str(random.randint(0, 9)) for _ in range(6))  # ç®€åŒ–åœ°å€ç 
                    year = str(random.randint(1950, 2005))  # éšæœºå¹´ä»½
                    month = f"{random.randint(1, 12):02d}"  # æœˆä»½è¡¥0
                    day = f"{random.randint(1, 28):02d}"  # æ—¥æœŸç®€åŒ–å¤„ç†ï¼ˆ1-28ï¼‰
                    birth_code = year + month + day
                    seq_code = ''.join(str(random.randint(0, 9)) for _ in range(3))  # é¡ºåºç 
                    last_code = random.choice([str(i) for i in range(10)] + ['X'])  # æ ¡éªŒç ï¼ˆå¯èƒ½ä¸ºXï¼‰
                    id_card = address_code + birth_code + seq_code + last_code
                    result = [f"éšæœºç”Ÿæˆçš„18ä½èº«ä»½è¯å·ç ï¼š{id_card}"]
                else:
                    num_length = random.randint(4, 35)
                    num_str = str(random.randint(1000, 10**num_length))
                    result = [f"éšæœºç”Ÿæˆçš„é•¿åº¦ä¸º{num_length}çš„æ•°å­—{num_str}"]
            else:
                result = self.directions
            prompt = self.generation_prompt_builder(sample_data, self.variants_per_sample, self.special_prompt, result)
        
            # è°ƒç”¨APIç”Ÿæˆæ•°æ®
            response = await self.call_api(prompt, temperature=0.3)
            if response is None:
                logger.error("ç”Ÿæˆæ•°æ®APIè°ƒç”¨å¤±è´¥")
                return []
            
            # å¦‚æœæ˜¯ä¸»æ‰¹æ¬¡çš„ä¸»çº¿ç¨‹ï¼Œæ‰“å°æ¨¡å‹è¾“å‡º
            if is_main_batch and is_main_thread:
                logger.info("=" * 80)
                logger.info("ã€ä¸»æ‰¹æ¬¡ä¸»çº¿ç¨‹ã€‘æ¨¡å‹åŸå§‹è¾“å‡º")
                logger.info(f"æ‰¹æ¬¡ç´¢å¼•: {batch_idx}, çº¿ç¨‹ç´¢å¼•: {thread_idx}")
                logger.info("=" * 80)
                logger.info(response)
                logger.info("=" * 80)
            
            # è§£æç”Ÿæˆçš„æ•°æ®
            generated_list = self.parse_generated_data(response, batch_idx, thread_idx, is_main_batch, is_main_thread)
            logger.info(f"ğŸ“Š è§£æç»“æœï¼šgenerated_listé•¿åº¦={len(generated_list)}")
            if generated_list:
                logger.info(f"ğŸ“Š ç¬¬ä¸€ä¸ªgenerated_dataçš„ç»“æ„: {json.dumps(generated_list[0] if len(generated_list) > 0 else {}, ensure_ascii=False, indent=2)[:500]}")
            self.stats['data_generated'] += len(generated_list)
            return generated_list
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return []
    
    async def evaluate_generated_data(self, sample_data: Dict[str, Any], generated_data: Dict[str, Any]) -> Tuple[int, int]:
        """è¯„ä¼°ç”Ÿæˆçš„æ•°æ®ï¼Œè¿”å›(æ¨¡å‹è¯„åˆ†, è§„åˆ™è¯„åˆ†)"""
        try:
            # è·å–Assistantçš„å›ç­”ç”¨äºè§„åˆ™è¯„ä¼°
            assistant_text = ""
            # ä¿®å¤ï¼šturnsåº”è¯¥æ˜¯åˆ—è¡¨ï¼Œé»˜è®¤å€¼åº”è¯¥æ˜¯[]è€Œä¸æ˜¯{}
            turns = generated_data.get('turns', [])
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥turnsçš„ç±»å‹å’Œå†…å®¹
            if not isinstance(turns, list):
                logger.error(f"âš ï¸ è­¦å‘Šï¼šturnsä¸æ˜¯åˆ—è¡¨ç±»å‹ï¼ç±»å‹: {type(turns)}, å€¼: {turns}")
                logger.error(f"generated_dataç»“æ„: {json.dumps(generated_data, ensure_ascii=False, indent=2)}")
                return 0, 0
            
            for turn in turns:
                if not isinstance(turn, dict):
                    logger.error(f"âš ï¸ è­¦å‘Šï¼šturnä¸æ˜¯å­—å…¸ç±»å‹ï¼ç±»å‹: {type(turn)}, å€¼: {turn}")
                    continue
                if turn.get('role') == 'Assistant':
                    assistant_text = turn.get('text', '')
                    break
            
            Assistant = 0
            Human = 0
            for turn_idx, turn in enumerate(turns):
                if not isinstance(turn, dict):
                    logger.warning(f"âš ï¸ turn[{turn_idx}]ä¸æ˜¯å­—å…¸: {type(turn)}, å€¼: {turn}")
                    continue
                role = turn.get('role', '')
                # å¤„ç†roleå­—æ®µï¼šå»é™¤é¦–å°¾ç©ºæ ¼ï¼Œç»Ÿä¸€å¤§å°å†™
                if isinstance(role, str):
                    role = role.strip()
                # æ·»åŠ è°ƒè¯•ï¼šæ‰“å°æ¯ä¸ªturnçš„role
                logger.info(f"ğŸ” è°ƒè¯•ï¼šturn[{turn_idx}]çš„role='{role}' (åŸå§‹å€¼: '{turn.get('role', '')}', ç±»å‹: {type(role)})")
                if role == 'Assistant':
                    Assistant += 1
                    logger.info(f"  âœ… æ‰¾åˆ°Assistantï¼Œå½“å‰è®¡æ•°: {Assistant}")
                elif role == 'Human':
                    Human += 1
                    logger.info(f"  âœ… æ‰¾åˆ°Humanï¼Œå½“å‰è®¡æ•°: {Human}")
                    human_content = turn.get('text')
                    if human_content:
                        human_content = human_content.strip()
                        human_content = human_content.split("\n")
                else:
                    logger.warning(f"âš ï¸ turn[{turn_idx}]æœªçŸ¥çš„roleå€¼: '{role}' (åŸå§‹å€¼: '{turn.get('role', '')}', ç±»å‹: {type(role)})")
                    logger.warning(f"  turnå®Œæ•´å†…å®¹: {json.dumps(turn, ensure_ascii=False)}")
                    # if human_content[-1][:6] != "å®¢æˆ·å½“å‰è¾“å…¥":
                    #     print("'å®¢æˆ·å½“å‰è¾“å…¥'ä¸åœ¨å†…å®¹èŒƒå›´å†…")
                    #     return 0, 0
            # è§„åˆ™è¯„åˆ†
            rule_score = 0
            model_score = 0
            if Assistant == 1 and Human == 1:
                rule_score = self.format_evaluator(assistant_text)
                if rule_score == 10:
                    # æ¨¡å‹è¯„åˆ†
                    eval_prompt = self.evaluation_prompt_builder(sample_data, generated_data, self.special_prompt)
                    eval_response_list = []
                    for _ in range(1):
                        eval_response = await self.call_api(eval_prompt, temperature=0.2)
                        eval_response_list.append(eval_response)
                        model_score_ = self.parse_evaluation_score(eval_response)
                        if (model_score_ and model_score_ < self.min_score) or not model_score_:
                            logger.warning(f"æ¨¡å‹è¯„ä¼°å­˜åœ¨ä½äº{self.min_score}åˆ†æˆ–ç¼ºå¤±æ‰“åˆ†çš„æƒ…å†µï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
                            return 0, 0
                    if all(eval_response for eval_response in eval_response_list):
                        model_score_list = [self.parse_evaluation_score(eval_response) for eval_response in eval_response_list]
                        if all((model_score and model_score >= self.min_score) for model_score in model_score_list):
                            model_score = sum(model_score_list) / len(model_score_list)
                        else:
                            model_score = 0
                            logger.warning(f"æ¨¡å‹è¯„ä¼°å­˜åœ¨ä½äº{self.min_score}åˆ†æˆ–ç¼ºå¤±æ‰“åˆ†çš„æƒ…å†µï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
                        if model_score is None:
                            model_score = 0
                            logger.warning("æ¨¡å‹è¯„ä¼°è§£æå¤±è´¥ï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
                    else:
                        logger.warning("æ¨¡å‹è¯„ä¼°APIè°ƒç”¨å¤±è´¥ï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
                else:
                    logger.warning("è¾“å‡ºä¸ç¬¦åˆè§„åˆ™ï¼Œæ¨¡å‹é»˜è®¤è¯„åˆ†0åˆ†")
            else:
                logger.warning("ç”Ÿæˆçš„å¯¹è¯ä¸å…¨")
                logger.warning(f"Assistantçš„æ•°é‡ä¸º:{Assistant}, Humançš„æ•°é‡ä¸º:{Human}")
            self.stats['data_evaluated'] += 1
            return model_score, rule_score
            
        except Exception as e:
            logger.error(f"è¯„ä¼°æ•°æ®æ—¶å‡ºé”™: {str(e)}\né”™è¯¯çš„æ•°æ®æ˜¯:{json.dumps(generated_data, indent=4, ensure_ascii=False)}")
            return 0, 0
    

    async def evaluate_data(self, content: str) -> int:
        """è¯„ä¼°ç”Ÿæˆçš„æ•°æ®ï¼Œè¿”å›(æ¨¡å‹è¯„åˆ†, è§„åˆ™è¯„åˆ†)"""
        try:
            model_score = 0

            # æ¨¡å‹è¯„åˆ†
            eval_prompt = self.filter_prompt(content)
            eval_response_list = []
            for _ in range(1):
                eval_response = await self.call_api(eval_prompt, temperature=0.2)
                eval_response_list.append(eval_response)
                model_score_ = self.parse_evaluation_score(eval_response)
                if (model_score_ and model_score_ < self.min_score) or not model_score_:
                    logger.warning(f"æ¨¡å‹è¯„ä¼°å­˜åœ¨ä½äº{self.min_score}åˆ†æˆ–ç¼ºå¤±æ‰“åˆ†çš„æƒ…å†µï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
                    return model_score_, eval_response
            if all(eval_response for eval_response in eval_response_list):
                model_score_list = [self.parse_evaluation_score(eval_response) for eval_response in eval_response_list]
                if all((model_score and model_score >= self.min_score) for model_score in model_score_list):
                    model_score = sum(model_score_list) / len(model_score_list)
                else:
                    model_score = 0
                    logger.warning(f"æ¨¡å‹è¯„ä¼°å­˜åœ¨ä½äº{self.min_score}åˆ†æˆ–ç¼ºå¤±æ‰“åˆ†çš„æƒ…å†µï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
                if model_score is None:
                    model_score = 0
                    logger.warning("æ¨¡å‹è¯„ä¼°è§£æå¤±è´¥ï¼Œé»˜è®¤è¯„åˆ†0åˆ†")
            else:
                logger.warning("æ¨¡å‹è¯„ä¼°APIè°ƒç”¨å¤±è´¥ï¼Œé»˜è®¤è¯„åˆ†0åˆ†")

            return model_score_, eval_response
            
        except Exception as e:
            logger.error(f"è¯„ä¼°æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return 0, "è¯„åˆ†æ—¶å‡ºé”™"
    
    async def process_single_sample(self, sample_data: Dict[str, Any], batch_idx: int = None, thread_idx: int = None, is_main_batch: bool = False, is_main_thread: bool = False) -> List[Dict[str, Any]]:
        """å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œç”Ÿæˆå¹¶è¯„ä¼°æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆæ ¼æ•°æ®åˆ™é‡è¯•
        
        Args:
            sample_data: æ ·æœ¬æ•°æ®
            batch_idx: æ‰¹æ¬¡ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            thread_idx: çº¿ç¨‹/æ ·æœ¬ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            is_main_batch: æ˜¯å¦ä¸ºä¸»æ‰¹æ¬¡ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼‰
            is_main_thread: æ˜¯å¦ä¸ºä¸»çº¿ç¨‹ï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
        """
        for retry_count in range(self.sample_retry_times):
            try:
                # ç”Ÿæˆæ•°æ®
                generated_list = await self.generate_data_from_sample(sample_data, batch_idx, thread_idx, is_main_batch, is_main_thread)
                
                if not generated_list:
                    if retry_count < self.sample_retry_times - 1:
                        logger.warning(f"æœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ•°æ®ï¼Œå‡†å¤‡é‡è¯• ({retry_count + 1}/{self.sample_retry_times})")
                        self.stats['sample_retries'] += 1
                        continue
                    else:
                        logger.warning(f"é‡è¯•{self.sample_retry_times}æ¬¡åä»æœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ•°æ®")
                        return []
                
                # è¯„ä¼°æ¯ä¸ªç”Ÿæˆçš„æ•°æ®
                qualified_data = []
                
                for idx, generated_data in enumerate(generated_list):
                    # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥generated_dataçš„ç»“æ„
                    if not isinstance(generated_data, dict):
                        logger.error(f"âš ï¸ è­¦å‘Šï¼šgenerated_data[{idx}]ä¸æ˜¯å­—å…¸ç±»å‹ï¼ç±»å‹: {type(generated_data)}, å€¼: {generated_data}")
                        continue
                    if 'turns' not in generated_data:
                        logger.error(f"âš ï¸ è­¦å‘Šï¼šgenerated_data[{idx}]ä¸­æ²¡æœ‰'turns'å­—æ®µï¼")
                        logger.error(f"generated_dataç»“æ„: {json.dumps(generated_data, ensure_ascii=False, indent=2)}")
                        continue
                    
                    # æ·»åŠ è¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°turnsçš„å†…å®¹
                    turns = generated_data.get('turns', [])
                    logger.info(f"ğŸ” è°ƒè¯•ï¼šgenerated_data[{idx}]çš„turnså†…å®¹:")
                    logger.info(f"  turnsç±»å‹: {type(turns)}, é•¿åº¦: {len(turns) if isinstance(turns, list) else 'N/A'}")
                    if isinstance(turns, list):
                        for turn_idx, turn in enumerate(turns):
                            logger.info(f"  turn[{turn_idx}]: {json.dumps(turn, ensure_ascii=False)}")
                    else:
                        logger.error(f"  turnsä¸æ˜¯åˆ—è¡¨ï¼å€¼: {turns}")
                    
                    model_score, rule_score = await self.evaluate_generated_data(sample_data, generated_data)
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€ä½åˆ†æ•°è¦æ±‚ï¼šè§„åˆ™è¯„åˆ†å¿…é¡»æ»¡åˆ†ï¼Œæ¨¡å‹è¯„åˆ†è¾¾åˆ°æœ€ä½è¦æ±‚
                    if model_score >= self.min_score and rule_score == 10:
                        # æ„å»ºå®Œæ•´çš„æ•°æ®ç»“æ„
                        complete_data = {
                            'meta': sample_data.get('meta', {}).copy(),
                            'turns': generated_data.get('turns', [])
                        }
                        
                        # æ·»åŠ ç”Ÿæˆå…ƒæ•°æ®
                        complete_data['meta']['generated'] = True
                        complete_data['meta']['generation_model'] = self.model.split('/')[-1]
                        complete_data['meta']['generation_time'] = datetime.now().isoformat()
                        complete_data['meta']['model_score'] = model_score
                        complete_data['meta']['rule_score'] = rule_score
                        complete_data['meta']['source_task'] = self.task_type
                        complete_data['meta']['retry_count'] = retry_count  # è®°å½•é‡è¯•æ¬¡æ•°
                        
                        qualified_data.append(complete_data)
                        self.stats['data_passed'] += 1
                        logger.info(f"æ•°æ®é€šè¿‡è¯„ä¼° - æ¨¡å‹è¯„åˆ†: {model_score}, è§„åˆ™è¯„åˆ†: {rule_score} (é‡è¯•æ¬¡æ•°: {retry_count})")
                    else:
                        self.stats['data_failed'] += 1
                        if rule_score != 10:
                            logger.info(f"æ•°æ®æœªé€šè¿‡è¯„ä¼° - è§„åˆ™è¯„åˆ†æœªæ»¡åˆ†: {rule_score} (éœ€è¦10åˆ†), æ¨¡å‹è¯„åˆ†: {model_score}")
                        else:
                            logger.info(f"æ•°æ®æœªé€šè¿‡è¯„ä¼° - æ¨¡å‹è¯„åˆ†ä¸è¶³: {model_score} (éœ€è¦â‰¥{self.min_score}), è§„åˆ™è¯„åˆ†: {rule_score}")
                
                # å¦‚æœæœ‰åˆæ ¼æ•°æ®ï¼Œç›´æ¥è¿”å›
                if qualified_data:
                    return qualified_data
                
                # å¦‚æœæ²¡æœ‰åˆæ ¼æ•°æ®ä¸”è¿˜å¯ä»¥é‡è¯•
                if retry_count < self.sample_retry_times - 1:
                    logger.warning(f"æœ¬è½®æœªäº§ç”Ÿåˆæ ¼æ•°æ®ï¼Œå‡†å¤‡é‡è¯• ({retry_count + 1}/{self.sample_retry_times})")
                    self.stats['sample_retries'] += 1
                    continue
                else:
                    logger.warning(f"é‡è¯•{self.sample_retry_times}æ¬¡åä»æœªäº§ç”Ÿåˆæ ¼æ•°æ®")
                    return []
                
            except Exception as e:
                if retry_count < self.sample_retry_times - 1:
                    logger.error(f"å¤„ç†æ ·æœ¬æ—¶å‡ºé”™: {str(e)}ï¼Œå‡†å¤‡é‡è¯• ({retry_count + 1}/{self.sample_retry_times})")
                    self.stats['sample_retries'] += 1
                    continue
                else:
                    logger.error(f"é‡è¯•{self.sample_retry_times}æ¬¡åä»ç„¶å‡ºé”™: {str(e)}")
                    return []
        
        return []
    
    async def process_batch(self, samples: List[Dict[str, Any]], batch_idx: int = None, is_main_batch: bool = False) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†æ ·æœ¬
        
        Args:
            samples: æ ·æœ¬åˆ—è¡¨
            batch_idx: æ‰¹æ¬¡ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            is_main_batch: æ˜¯å¦ä¸ºä¸»æ‰¹æ¬¡ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼‰
        """
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def process_with_semaphore(sample, thread_idx):
            async with semaphore:
                # åˆ¤æ–­æ˜¯å¦ä¸ºä¸»çº¿ç¨‹ï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
                is_main_thread = (thread_idx == 0)
                return await self.process_single_sample(sample, batch_idx, thread_idx, is_main_batch, is_main_thread)
        
        tasks = [process_with_semaphore(sample, idx) for idx, sample in enumerate(samples)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æ‰€æœ‰åˆæ ¼çš„æ•°æ®
        all_qualified_data = []
        for result in results:
            if isinstance(result, list):
                all_qualified_data.extend(result)
            elif isinstance(result, Exception):
                logger.error(f"æ‰¹å¤„ç†ä¸­å‡ºç°å¼‚å¸¸: {result}")
        
        return all_qualified_data
    
    async def generate_from_file(self, input_file: str, output_file: str, batch_size: int = 5):
        """ä»æ–‡ä»¶ç”Ÿæˆæ•°æ®"""
        logger.info(f"å¼€å§‹ä»æ–‡ä»¶ç”Ÿæˆæ•°æ®: {input_file}")
        
        # åˆå§‹åŒ–ä¼šè¯
        await self.init_session()
        
        try:
            # è¯»å–æ ·æœ¬æ–‡ä»¶
            samples = []
            with open(input_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        samples.append(data)
                        self.stats['samples_read'] += 1
                    except json.JSONDecodeError as e:
                        logger.warning(f"ç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥: {e}")
            
            logger.info(f"å…±è¯»å– {len(samples)} ä¸ªæ ·æœ¬")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # åˆ†æ‰¹å¤„ç†
            all_qualified_data = []
            with open(output_file, 'w', encoding='utf-8') as out_f:
                for i in range(0, len(samples), batch_size):
                    batch = samples[i:i + batch_size]
                    batch_idx = i // batch_size
                    is_main_batch = (batch_idx == 0)  # ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ä¸ºä¸»æ‰¹æ¬¡
                    logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{(len(samples) + batch_size - 1)//batch_size}")
                    
                    # å¤„ç†å½“å‰æ‰¹æ¬¡
                    batch_results = await self.process_batch(batch, batch_idx, is_main_batch)
                    
                    # ç«‹å³å†™å…¥åˆæ ¼çš„æ•°æ®
                    for qualified_data in batch_results:
                        json_line = json.dumps(qualified_data, ensure_ascii=False)
                        out_f.write(json_line + '\n')
                    
                    all_qualified_data.extend(batch_results)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (i + len(batch)) / len(samples) * 100
                    logger.info(f"è¿›åº¦: {progress:.1f}% (å·²ç”Ÿæˆåˆæ ¼æ•°æ®: {len(all_qualified_data)} æ¡)")
            
            logger.info(f"æ•°æ®ç”Ÿæˆå®Œæˆ! ç»Ÿè®¡: {self.stats}")
            logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
            logger.info(f"æ€»è®¡ç”Ÿæˆåˆæ ¼æ•°æ®: {len(all_qualified_data)} æ¡")
        
        finally:
            await self.close_session()


def test_api_connection(api_base: str) -> bool:
    """æµ‹è¯•APIè¿æ¥"""
    import requests
    try:
        response = requests.get(f"{api_base}/models", timeout=10)
        if response.status_code == 200:
            models = response.json()
            logger.info(f"APIè¿æ¥æˆåŠŸï¼Œå¯ç”¨æ¨¡å‹: {[m['id'] for m in models.get('data', [])]}")
            return True
        else:
            logger.error(f"APIè¿æ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main_process(input_file, output_file, api_base, model, batch_size, max_concurrent, retry_times, min_score, task_type, variants_per_sample, sample_retry_times, special_prompt, directions):
    
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(input_file):
            logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return
        
        # æµ‹è¯•APIè¿æ¥
        logger.info("æµ‹è¯•APIè¿æ¥...")
        if not test_api_connection(api_base):
            logger.error("APIè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            return
        
        # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
        generator = DataGenerator(
            api_base=api_base,
            model=model,
            max_concurrent=max_concurrent,
            retry_times=retry_times,
            min_score=min_score,
            task_type=task_type,
            variants_per_sample=variants_per_sample,
            sample_retry_times=sample_retry_times,
            special_prompt=special_prompt,
            directions=directions
        )
        
        # å¼€å§‹ç”Ÿæˆæ•°æ®
        start_time = time.time()
        await generator.generate_from_file(input_file, output_file, batch_size)
        end_time = time.time()
        
        logger.info(f"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

        return {"status": "Sucessed"}
    except Exception as e:
        return {"status": "Failed"}

def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ç”Ÿæˆæ–°çš„å¯¹è¯æ•°æ®')
    parser.add_argument('--input_file', help='è¾“å…¥çš„æ ·æœ¬JSONLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_file', '-o', required=True, help='è¾“å‡ºçš„JSONLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--api-base', default='http://localhost:6466/v1', help='APIæœåŠ¡åœ°å€')
    parser.add_argument('--model', default='/data/models/Qwen3-32B', help='æ¨¡å‹åç§°')
    parser.add_argument('--batch-size', type=int, default=1, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--max-concurrent', type=int, default=5, help='æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('--retry-times', type=int, default=3, help='é‡è¯•æ¬¡æ•°')
    parser.add_argument('--min-score', type=int, default=8, help='æœ€ä½è¯„åˆ†è¦æ±‚(0-10)')
    parser.add_argument('--task-type', default='entity_extraction', help='ä»»åŠ¡ç±»å‹')
    parser.add_argument('--variants-per-sample', type=int, default=1, help='æ¯ä¸ªæ ·æœ¬ç”Ÿæˆçš„å˜ä½“æ•°é‡')
    parser.add_argument('--sample-retry-times', type=int, default=1, help='æ ·æœ¬å¤„ç†é‡è¯•æ¬¡æ•°')
    
    args = parser.parse_args()
    asyncio.run(main_process(args.input_file, args.output, args.api_base, args.model, args.batch_size, args.max_concurrent, args.retry_times, args.min_score, args.task_type, args.variants_per_sample, args.sample_retry_times)) 


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    main()